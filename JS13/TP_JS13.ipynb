{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b712a2",
   "metadata": {},
   "source": [
    "# Tugas Praktikum\n",
    "Gunakan JST untuk klasifikasi angka tulisan tangan (MNIST).\n",
    "\n",
    "Langkah:\n",
    "\n",
    "Load dataset MNIST dari Keras.\n",
    "\n",
    "Bangun model dengan 2 hidden layer.\n",
    "\n",
    "Latih model dan evaluasi akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Data siap! Ukuran gambar: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time # Untuk menghitung durasi training\n",
    "\n",
    "# 1. Load dataset MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalisasi data (0-255 -> 0-1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One-hot encoding label (Misal angka 5 jadi [0,0,0,0,0,1,0,0,0,0])\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Data siap! Ukuran gambar:\", X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latih_model(nama_eksperimen, neurons_list, activation_func):\n",
    "    print(f\"\\n=== {nama_eksperimen} ===\")\n",
    "\n",
    "    model = Sequential()\n",
    "    # Layer Input (Flatten mengubah gambar 28x28 jadi vektor 784)\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Menambahkan Hidden Layers secara dinamis sesuai list\n",
    "    for n in neurons_list:\n",
    "        model.add(Dense(n, activation=activation_func))\n",
    "\n",
    "    # Output Layer (Selalu 10 neuron untuk angka 0-9, pakai Softmax)\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Kompilasi\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Latih & Hitung Waktu\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.1, verbose=1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Evaluasi\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"-> Waktu Pelatihan: {end_time - start_time:.2f} detik\")\n",
    "    print(f\"-> Akurasi Test: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64d762",
   "metadata": {},
   "source": [
    "Ubah jumlah neuron di hidden layer (misal: 256 dan 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2538a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Awal (128, 64) - ReLU ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.6816 - val_accuracy: 0.9592 - val_loss: 0.1429\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1545 - val_accuracy: 0.9698 - val_loss: 0.1094\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.1023 - val_accuracy: 0.9728 - val_loss: 0.0947\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0775 - val_accuracy: 0.9755 - val_loss: 0.0832\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0610 - val_accuracy: 0.9768 - val_loss: 0.0750\n",
      "-> Waktu Pelatihan: 14.27 detik\n",
      "-> Akurasi Test: 0.9767\n",
      "\n",
      "=== Tugas Ubah Neuron (256, 128) - ReLU ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.5219 - val_accuracy: 0.9675 - val_loss: 0.1188\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1185 - val_accuracy: 0.9735 - val_loss: 0.0904\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0717 - val_accuracy: 0.9735 - val_loss: 0.0902\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0496 - val_accuracy: 0.9720 - val_loss: 0.0992\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0401 - val_accuracy: 0.9782 - val_loss: 0.0761\n",
      "-> Waktu Pelatihan: 21.40 detik\n",
      "-> Akurasi Test: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9785000085830688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Skenario 1: Model Standard (Misal 128 dan 64)\n",
    "latih_model(\"Model Awal (128, 64) - ReLU\", [128, 64], 'relu')\n",
    "\n",
    "# Skenario 2: Perintah Tugas (Ubah neuron jadi 256 dan 128)\n",
    "latih_model(\"Tugas Ubah Neuron (256, 128) - ReLU\", [256, 128], 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fe31e",
   "metadata": {},
   "source": [
    "\n",
    "Tambahkan satu hidden layer lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tugas Tambah Layer (256, 128, 64) - ReLU ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.5762 - val_accuracy: 0.9642 - val_loss: 0.1164\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.1173 - val_accuracy: 0.9747 - val_loss: 0.0853\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0708 - val_accuracy: 0.9778 - val_loss: 0.0786\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0505 - val_accuracy: 0.9710 - val_loss: 0.0916\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0401 - val_accuracy: 0.9800 - val_loss: 0.0703\n",
      "-> Waktu Pelatihan: 16.08 detik\n",
      "-> Akurasi Test: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9790999889373779"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Skenario 3: Tambah 1 Layer (256, 128, 64)\n",
    "latih_model(\"Tugas Tambah Layer (256, 128, 64) - ReLU\", [256, 128, 64], 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d897779",
   "metadata": {},
   "source": [
    "Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eksperimen Sigmoid (256, 128) - Sigmoid ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 1.1205 - val_accuracy: 0.9323 - val_loss: 0.2429\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2693 - val_accuracy: 0.9507 - val_loss: 0.1739\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1922 - val_accuracy: 0.9605 - val_loss: 0.1416\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.1517 - val_accuracy: 0.9640 - val_loss: 0.1273\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9650 - loss: 0.1203 - val_accuracy: 0.9715 - val_loss: 0.1004\n",
      "-> Waktu Pelatihan: 18.77 detik\n",
      "-> Akurasi Test: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9660000205039978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Skenario 4: Pakai Sigmoid (Struktur sama dengan Skenario 2)\n",
    "latih_model(\"Eksperimen Sigmoid (256, 128) - Sigmoid\", [256, 128], 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b9567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eksperimen Sigmoid (256, 128) - Sigmoid ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5638 - loss: 1.4988 - val_accuracy: 0.9292 - val_loss: 0.2806\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2868 - val_accuracy: 0.9557 - val_loss: 0.1691\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9462 - loss: 0.1880 - val_accuracy: 0.9663 - val_loss: 0.1277\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.1403 - val_accuracy: 0.9682 - val_loss: 0.1133\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.1057 - val_accuracy: 0.9722 - val_loss: 0.0953\n",
      "-> Waktu Pelatihan: 17.79 detik\n",
      "-> Akurasi Test: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9678999781608582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Skenario 5: Pakai Sigmoid (Struktur sama dengan Skenario 3)\n",
    "latih_model(\"Eksperimen Sigmoid (256, 128) - Sigmoid\", [256, 128, 64], 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdad5d",
   "metadata": {},
   "source": [
    "Bandingkan akurasi dan waktu pelatihan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bda245",
   "metadata": {},
   "source": [
    "### Tabel Rangkuman Hasil\n",
    "\n",
    "| Skenario | Konfigurasi Neurons | Fungsi Aktivasi | Waktu Training (detik) | Akurasi Test |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **1 (Baseline)** | [128, 64] | **ReLU** | **14.27s** (Tercepat) | 97.67% |\n",
    "| **2 (Large)** | [256, 128] | **ReLU** | 21.40s (Terlama) | 97.85% |\n",
    "| **3 (Deep)** | [256, 128, 64] | **ReLU** | 16.08s | **97.91%** (Tertinggi) |\n",
    "| **4 (Sigmoid)**| [256, 128] | Sigmoid | 18.77s | 96.60% |\n",
    "| **5 (Deep Sig)**| [256, 128, 64] | Sigmoid | 17.79s | 96.79% |\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Analisis Perbandingan Akurasi\n",
    "\n",
    "**A. Pemenang: Skenario 3 (Deep ReLU)**\n",
    "* **Hasil:** 97.91%\n",
    "* **Analisis:** Menambahkan kedalaman (*depth*) dengan 3 hidden layer memberikan hasil terbaik. Neural Network yang lebih dalam (\"Deep\") mampu memecah fitur gambar menjadi hierarki yang lebih kompleks (misal: layer 1 mendeteksi garis, layer 2 mendeteksi lengkungan, layer 3 mendeteksi bentuk angka utuh).\n",
    "* **Kesimpulan:** Untuk MNIST, struktur yang lebih dalam sedikit lebih unggul daripada struktur yang sekadar lebar (banyak neuron).\n",
    "\n",
    "**B. Efek Jumlah Neuron (Skenario 1 vs 2)**\n",
    "* **Hasil:** 97.67% -> 97.85%\n",
    "* **Analisis:** Melipatgandakan jumlah neuron (dari 128 ke 256) memang meningkatkan akurasi, tetapi kenaikannya sangat tipis (hanya **+0.18%**).\n",
    "* **Kesimpulan:** Ini adalah fenomena *Diminishing Returns*. Menambah kapasitas model secara berlebihan tidak selalu memberikan lonjakan performa yang sebanding, karena model baseline pun sudah cukup mampu menangani data MNIST yang sederhana.\n",
    "\n",
    "**C. ReLU vs Sigmoid (Kekalahan Telak Sigmoid)**\n",
    "* **Perbandingan:** Skenario 2 (ReLU) 97.85% vs Skenario 4 (Sigmoid) 96.60%.\n",
    "* **Drop Akurasi:** Terjadi penurunan sekitar **1.25%** saat menggunakan Sigmoid.\n",
    "* **Analisis Loss Awal:** Perhatikan *Loss* pada Epoch 1:\n",
    "    * ReLU (Scen 2): Loss awal **0.52**\n",
    "    * Sigmoid (Scen 5): Loss awal **1.49**\n",
    "* **Penyebab:** Sigmoid mengalami masalah **Vanishing Gradient**. Gradien (turunan) pada fungsi Sigmoid sangat kecil di kedua ujung kurva. Ini menyebabkan *update* bobot berlangsung lambat. Model ReLU langsung belajar cepat sejak Epoch 1, sedangkan Sigmoid \"berjuang\" untuk menurunkan error.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Analisis Waktu Pelatihan (Efisiensi)\n",
    "\n",
    "**A. Model Tercepat: Skenario 1**\n",
    "* Hanya butuh **14.27 detik**. Karena jumlah parameternya paling sedikit, komputasi matriksnya paling ringan. Ini adalah model paling efisien.\n",
    "\n",
    "**B. Anomali Waktu Skenario 2 vs 3**\n",
    "* Secara teori, Skenario 3 (3 layer) harusnya sedikit lebih berat atau setara dengan Skenario 2. Namun, di hasil, Skenario 3 (**16.08s**) justru lebih cepat dari Skenario 2 (**21.40s**).\n",
    "* **Penyebab:** Ini kemungkinan besar disebabkan oleh variabilitas *system load* (beban CPU/RAM komputer saat itu) atau optimasi cache. Namun secara umum, Skenario 2 memiliki layer pertama yang besar (input 784 ke 256) yang memakan memori besar.\n",
    "\n",
    "**C. Sigmoid Lebih Lambat Konvergen**\n",
    "* Meskipun waktu komputasi per detiknya mirip, Sigmoid membutuhkan lebih banyak Epoch untuk mencapai akurasi yang sama dengan ReLU. Melihat *Val Accuracy* pada Epoch 1:\n",
    "    * ReLU (Scen 3): **96.42%** (Langsung pintar di epoch 1)\n",
    "    * Sigmoid (Scen 5): **92.92%** (Masih belajar)\n",
    "\n",
    "---\n",
    "\n",
    "### Kesimpulan Akhir & Rekomendasi\n",
    "\n",
    "1.  **Aktivasi Terbaik:** Gunakan **ReLU**. Sigmoid terbukti lebih lambat belajar dan menghasilkan akurasi akhir yang lebih rendah untuk hidden layer pada kasus ini.\n",
    "2.  **Arsitektur Terbaik:** **Skenario 3 ([256, 128, 64])**. Kombinasi neuron yang cukup besar dengan kedalaman 3 layer memberikan keseimbangan terbaik untuk akurasi tertinggi.\n",
    "3.  **Efisiensi:** Jika memiliki keterbatasan *resource* komputer, **Skenario 1** adalah pilihan terbaik karena akurasinya (97.6%) hampir menyamai model yang jauh lebih berat, namun dengan waktu pelatihan paling singkat.\n",
    "\n",
    "\n",
    "\n",
    "Grafik imajiner di atas akan menunjukkan garis *Loss* ReLU yang turun tajam mendekati nol dalam 1-2 epoch, sementara garis *Loss* Sigmoid melandai perlahan."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
