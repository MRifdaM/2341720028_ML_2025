{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDqNTrKZjwHf"
   },
   "source": [
    "# Praktikum 1\n",
    "Praktikum 1 ini akan membuat JST sederhana (2 layer) dengan forward pass dan backpropagation manual.\n",
    "\n",
    "Backpropagation adalah sebuah algoritma untuk melatih jaringan saraf tiruan dengan cara mengoreksi kesalahan. Algoritma ini bekerja dengan cara menghitung selisih antara keluaran yang dihasilkan jaringan dan keluaran yang seharusnya (kesalahan), lalu memperbarui bobot dan bias jaringan secara berulang dari keluaran ke masukan untuk meminimalkan kesalahan tersebut. Cara kerja backpropagation\n",
    "\n",
    "* Perambatan maju (forward pass): Data masukan diproses melalui jaringan dari lapisan masukan ke lapisan keluaran untuk menghasilkan prediksi awal.\n",
    "\n",
    "* Hitung kesalahan: Selisih antara keluaran prediksi dan keluaran target dihitung menggunakan fungsi kerugian.\n",
    "\n",
    "* Perambatan mundur (backward pass): Kesalahan disebarkan kembali ke belakang melalui jaringan dari lapisan keluaran ke lapisan masukan untuk menghitung gradien atau turunan parsial dari fungsi kerugian terhadap bobot dan bias.\n",
    "\n",
    "* Perbarui bobot: Bobot dan bias disesuaikan menggunakan algoritma penurunan gradien untuk mengurangi kesalahan pada iterasi berikutnya.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "1. Buat dataset sederhana (XOR).\n",
    "\n",
    "2. Inisialisasi bobot dan bias.\n",
    "\n",
    "3. Implementasikan forward pass.\n",
    "\n",
    "4. Hitung error dan lakukan backpropagation.\n",
    "\n",
    "5. Update bobot menggunakan gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1763613613205,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "gP06acdzjSd7",
    "outputId": "b1353f8c-ca4c-4b76-ebea-8e8d76e43065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2515602296598757\n",
      "Epoch 1000, Loss: 0.23341230367559063\n",
      "Epoch 2000, Loss: 0.08671440084882305\n",
      "Epoch 3000, Loss: 0.020279645185497085\n",
      "Epoch 4000, Loss: 0.009678141995360512\n",
      "Epoch 5000, Loss: 0.006093334619251125\n",
      "Epoch 6000, Loss: 0.004372570076005217\n",
      "Epoch 7000, Loss: 0.0033809554155657916\n",
      "Epoch 8000, Loss: 0.0027424191264224973\n",
      "Epoch 9000, Loss: 0.002299509321458016\n",
      "Prediksi:\n",
      "[[0.04492787]\n",
      " [0.94960592]\n",
      " [0.95774314]\n",
      " [0.03949024]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34CUQ1YnkEWG"
   },
   "source": [
    "# Tugas 1:\n",
    "\n",
    "* Ubah jumlah neuron hidden layer menjadi 3.\n",
    "\n",
    "* Bandingkan hasil loss dengan konfigurasi awal.\n",
    "\n",
    "* Tambahkan fungsi aktivasi ReLU dan bandingkan hasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1763615965725,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "3Dlwff0WsuJ7",
    "outputId": "9ae58320-a237-4f9f-fba5-882fd22f94a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Data siap! Ukuran gambar: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time # Untuk menghitung durasi training\n",
    "\n",
    "# 1. Load dataset MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalisasi data (0-255 -> 0-1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One-hot encoding label (Misal angka 5 jadi [0,0,0,0,0,1,0,0,0,0])\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Data siap! Ukuran gambar:\", X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1763615977639,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "EmxHTZA0tAle"
   },
   "outputs": [],
   "source": [
    "def latih_model(nama_eksperimen, neurons_list, activation_func):\n",
    "    print(f\"\\n=== {nama_eksperimen} ===\")\n",
    "\n",
    "    model = Sequential()\n",
    "    # Layer Input (Flatten mengubah gambar 28x28 jadi vektor 784)\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Menambahkan Hidden Layers secara dinamis sesuai list\n",
    "    for n in neurons_list:\n",
    "        model.add(Dense(n, activation=activation_func))\n",
    "\n",
    "    # Output Layer (Selalu 10 neuron untuk angka 0-9, pakai Softmax)\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Kompilasi\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Latih & Hitung Waktu\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.1, verbose=1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Evaluasi\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"-> Waktu Pelatihan: {end_time - start_time:.2f} detik\")\n",
    "    print(f\"-> Akurasi Test: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL-MmISstHrI"
   },
   "source": [
    "Ubah jumlah neuron di hidden layer (misal: 256 dan 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37824,
     "status": "ok",
     "timestamp": 1763616159908,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "HqRvaAfEtIWP",
    "outputId": "b1a3aab0-901f-4662-a800-c1dc651f471b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Awal (128, 64) - ReLU ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.6816 - val_accuracy: 0.9592 - val_loss: 0.1429\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1545 - val_accuracy: 0.9698 - val_loss: 0.1094\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.1023 - val_accuracy: 0.9728 - val_loss: 0.0947\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0775 - val_accuracy: 0.9755 - val_loss: 0.0832\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0610 - val_accuracy: 0.9768 - val_loss: 0.0750\n",
      "-> Waktu Pelatihan: 14.27 detik\n",
      "-> Akurasi Test: 0.9767\n",
      "\n",
      "=== Tugas Ubah Neuron (256, 128) - ReLU ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.5219 - val_accuracy: 0.9675 - val_loss: 0.1188\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1185 - val_accuracy: 0.9735 - val_loss: 0.0904\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0717 - val_accuracy: 0.9735 - val_loss: 0.0902\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0496 - val_accuracy: 0.9720 - val_loss: 0.0992\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0401 - val_accuracy: 0.9782 - val_loss: 0.0761\n",
      "-> Waktu Pelatihan: 21.40 detik\n",
      "-> Akurasi Test: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9785000085830688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skenario 1: Model Standard (Misal 128 dan 64)\n",
    "latih_model(\"Model Awal (128, 64) - ReLU\", [128, 64], 'relu')\n",
    "\n",
    "# Skenario 2: Perintah Tugas (Ubah neuron jadi 256 dan 128)\n",
    "latih_model(\"Tugas Ubah Neuron (256, 128) - ReLU\", [256, 128], 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlVgCMYOtnQi"
   },
   "source": [
    "\n",
    "Tambahkan satu hidden layer lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17483,
     "status": "ok",
     "timestamp": 1763616177393,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "WhbsMW6ftr3k",
    "outputId": "54ac4e41-355e-4122-f3d1-14c125b08997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tugas Tambah Layer (256, 128, 64) - ReLU ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.5762 - val_accuracy: 0.9642 - val_loss: 0.1164\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.1173 - val_accuracy: 0.9747 - val_loss: 0.0853\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0708 - val_accuracy: 0.9778 - val_loss: 0.0786\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0505 - val_accuracy: 0.9710 - val_loss: 0.0916\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0401 - val_accuracy: 0.9800 - val_loss: 0.0703\n",
      "-> Waktu Pelatihan: 16.08 detik\n",
      "-> Akurasi Test: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9790999889373779"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skenario 3: Tambah 1 Layer (256, 128, 64)\n",
    "latih_model(\"Tugas Tambah Layer (256, 128, 64) - ReLU\", [256, 128, 64], 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNdk6W3Itwb4"
   },
   "source": [
    "Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19460,
     "status": "ok",
     "timestamp": 1763616250097,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "gmjIOvBetwmS",
    "outputId": "481a65ca-8ade-4184-b088-edb24c83694f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eksperimen Sigmoid (256, 128) - Sigmoid ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 1.1205 - val_accuracy: 0.9323 - val_loss: 0.2429\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2693 - val_accuracy: 0.9507 - val_loss: 0.1739\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1922 - val_accuracy: 0.9605 - val_loss: 0.1416\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.1517 - val_accuracy: 0.9640 - val_loss: 0.1273\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9650 - loss: 0.1203 - val_accuracy: 0.9715 - val_loss: 0.1004\n",
      "-> Waktu Pelatihan: 18.77 detik\n",
      "-> Akurasi Test: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9660000205039978"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skenario 4: Pakai Sigmoid (Struktur sama dengan Skenario 2)\n",
    "latih_model(\"Eksperimen Sigmoid (256, 128) - Sigmoid\", [256, 128], 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18450,
     "status": "ok",
     "timestamp": 1763616287454,
     "user": {
      "displayName": "Muhammad Rifda Musyaffa",
      "userId": "01882048640543815797"
     },
     "user_tz": -420
    },
    "id": "eLm_lE3ZuGCg",
    "outputId": "463c430c-995c-48c0-80f0-8d302d63fdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eksperimen Sigmoid (256, 128) - Sigmoid ===\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5638 - loss: 1.4988 - val_accuracy: 0.9292 - val_loss: 0.2806\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2868 - val_accuracy: 0.9557 - val_loss: 0.1691\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9462 - loss: 0.1880 - val_accuracy: 0.9663 - val_loss: 0.1277\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.1403 - val_accuracy: 0.9682 - val_loss: 0.1133\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.1057 - val_accuracy: 0.9722 - val_loss: 0.0953\n",
      "-> Waktu Pelatihan: 17.79 detik\n",
      "-> Akurasi Test: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9678999781608582"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skenario 5: Pakai Sigmoid (Struktur sama dengan Skenario 3)\n",
    "latih_model(\"Eksperimen Sigmoid (256, 128) - Sigmoid\", [256, 128, 64], 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3erNHuz2uKk3"
   },
   "source": [
    "Bandingkan akurasi dan waktu pelatihan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vT7ZUwPwu7Z-"
   },
   "source": [
    "### Tabel Rangkuman Hasil\n",
    "\n",
    "| Skenario | Konfigurasi Neurons | Fungsi Aktivasi | Waktu Training (detik) | Akurasi Test |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **1 (Baseline)** | [128, 64] | **ReLU** | **14.27s** (Tercepat) | 97.67% |\n",
    "| **2 (Large)** | [256, 128] | **ReLU** | 21.40s (Terlama) | 97.85% |\n",
    "| **3 (Deep)** | [256, 128, 64] | **ReLU** | 16.08s | **97.91%** (Tertinggi) |\n",
    "| **4 (Sigmoid)**| [256, 128] | Sigmoid | 18.77s | 96.60% |\n",
    "| **5 (Deep Sig)**| [256, 128, 64] | Sigmoid | 17.79s | 96.79% |\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Analisis Perbandingan Akurasi\n",
    "\n",
    "**A. Pemenang: Skenario 3 (Deep ReLU)**\n",
    "* **Hasil:** 97.91%\n",
    "* **Analisis:** Menambahkan kedalaman (*depth*) dengan 3 hidden layer memberikan hasil terbaik. Neural Network yang lebih dalam (\"Deep\") mampu memecah fitur gambar menjadi hierarki yang lebih kompleks (misal: layer 1 mendeteksi garis, layer 2 mendeteksi lengkungan, layer 3 mendeteksi bentuk angka utuh).\n",
    "* **Kesimpulan:** Untuk MNIST, struktur yang lebih dalam sedikit lebih unggul daripada struktur yang sekadar lebar (banyak neuron).\n",
    "\n",
    "**B. Efek Jumlah Neuron (Skenario 1 vs 2)**\n",
    "* **Hasil:** 97.67% -> 97.85%\n",
    "* **Analisis:** Melipatgandakan jumlah neuron (dari 128 ke 256) memang meningkatkan akurasi, tetapi kenaikannya sangat tipis (hanya **+0.18%**).\n",
    "* **Kesimpulan:** Ini adalah fenomena *Diminishing Returns*. Menambah kapasitas model secara berlebihan tidak selalu memberikan lonjakan performa yang sebanding, karena model baseline pun sudah cukup mampu menangani data MNIST yang sederhana.\n",
    "\n",
    "**C. ReLU vs Sigmoid (Kekalahan Telak Sigmoid)**\n",
    "* **Perbandingan:** Skenario 2 (ReLU) 97.85% vs Skenario 4 (Sigmoid) 96.60%.\n",
    "* **Drop Akurasi:** Terjadi penurunan sekitar **1.25%** saat menggunakan Sigmoid.\n",
    "* **Analisis Loss Awal:** Perhatikan *Loss* pada Epoch 1:\n",
    "    * ReLU (Scen 2): Loss awal **0.52**\n",
    "    * Sigmoid (Scen 5): Loss awal **1.49**\n",
    "* **Penyebab:** Sigmoid mengalami masalah **Vanishing Gradient**. Gradien (turunan) pada fungsi Sigmoid sangat kecil di kedua ujung kurva. Ini menyebabkan *update* bobot berlangsung lambat. Model ReLU langsung belajar cepat sejak Epoch 1, sedangkan Sigmoid \"berjuang\" untuk menurunkan error.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Analisis Waktu Pelatihan (Efisiensi)\n",
    "\n",
    "**A. Model Tercepat: Skenario 1**\n",
    "* Hanya butuh **14.27 detik**. Karena jumlah parameternya paling sedikit, komputasi matriksnya paling ringan. Ini adalah model paling efisien.\n",
    "\n",
    "**B. Anomali Waktu Skenario 2 vs 3**\n",
    "* Secara teori, Skenario 3 (3 layer) harusnya sedikit lebih berat atau setara dengan Skenario 2. Namun, di hasil, Skenario 3 (**16.08s**) justru lebih cepat dari Skenario 2 (**21.40s**).\n",
    "* **Penyebab:** Ini kemungkinan besar disebabkan oleh variabilitas *system load* (beban CPU/RAM komputer saat itu) atau optimasi cache. Namun secara umum, Skenario 2 memiliki layer pertama yang besar (input 784 ke 256) yang memakan memori besar.\n",
    "\n",
    "**C. Sigmoid Lebih Lambat Konvergen**\n",
    "* Meskipun waktu komputasi per detiknya mirip, Sigmoid membutuhkan lebih banyak Epoch untuk mencapai akurasi yang sama dengan ReLU. Melihat *Val Accuracy* pada Epoch 1:\n",
    "    * ReLU (Scen 3): **96.42%** (Langsung pintar di epoch 1)\n",
    "    * Sigmoid (Scen 5): **92.92%** (Masih belajar)\n",
    "\n",
    "---\n",
    "\n",
    "### Kesimpulan Akhir & Rekomendasi\n",
    "\n",
    "1.  **Aktivasi Terbaik:** Gunakan **ReLU**. Sigmoid terbukti lebih lambat belajar dan menghasilkan akurasi akhir yang lebih rendah untuk hidden layer pada kasus ini.\n",
    "2.  **Arsitektur Terbaik:** **Skenario 3 ([256, 128, 64])**. Kombinasi neuron yang cukup besar dengan kedalaman 3 layer memberikan keseimbangan terbaik untuk akurasi tertinggi.\n",
    "3.  **Efisiensi:** Jika memiliki keterbatasan *resource* komputer, **Skenario 1** adalah pilihan terbaik karena akurasinya (97.6%) hampir menyamai model yang jauh lebih berat, namun dengan waktu pelatihan paling singkat.\n",
    "\n",
    "\n",
    "\n",
    "Grafik imajiner di atas akan menunjukkan garis *Loss* ReLU yang turun tajam mendekati nol dalam 1-2 epoch, sementara garis *Loss* Sigmoid melandai perlahan."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3AO/QHbFRbDqjTp51Npb9",
   "collapsed_sections": [
    "FDqNTrKZjwHf"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
