{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16151697",
   "metadata": {},
   "source": [
    "# Praktikum 2\n",
    "Padaa praktikum ini kita akan menggunakan library Keras untuk menggunakan JST. Keras adalah API tingkat tinggi untuk membangun JST dengan mudah, sedangkan TensorFlow adalah framework yang mendukung Keras.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "1. Import library.\n",
    "\n",
    "2. Load dataset.\n",
    "\n",
    "3. Bangun model.\n",
    "\n",
    "4. Kompilasi dan latih model.\n",
    "\n",
    "5. Evaluasi hasil.\n",
    "\n",
    "Klasifikasi Data Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4adf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2725 - loss: 1.5837   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3113 - loss: 1.3453 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3198 - loss: 1.1561 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3978 - loss: 1.1048 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6445 - loss: 1.0531 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 1.0400 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6256 - loss: 1.0326 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 1.0191 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.9908 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.9903 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.9756 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.9521 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.9399 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.9379 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.9054 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.8951 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.8758 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.8486 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.8506 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.8158 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.7999 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.7971 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.7429 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.7163 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.6950 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.6885 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.6297 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.6575 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.5797 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.5980 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.5413 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.4996 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.5367 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.5037 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.4832 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.4422 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.4395 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.4131 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.3861 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.3903 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.3760 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.3453 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.3308 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.3321 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.3217 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.3279 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.2844 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.2976 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.2639 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.2813 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2757\n",
      "Akurasi: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Bangun model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Kompilasi\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Latih model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "\n",
    "# Evaluasi\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Akurasi: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336be53",
   "metadata": {},
   "source": [
    "# Tugas 2\n",
    "\n",
    "Ubah jumlah neuron hidden layer.\n",
    "\n",
    "Bandingkan akurasi dengan konfigurasi awal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377658c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODEL MODIFIKASI NEURON (20 & 16) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifikasi Neuron - Loss: 0.1337, Akurasi: 1.0000\n",
      "Result: Menambah neuron tidak berpengaruh signifikan/menurunkan performa (overfitting).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- MODEL MODIFIKASI NEURON (20 & 16) ---\")\n",
    "\n",
    "model_neuron = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu', input_shape=(4,)), # Diperbesar ke 20\n",
    "    tf.keras.layers.Dense(16, activation='relu'),                   # Diperbesar ke 16\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_neuron.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_neuron = model_neuron.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "loss_neuron, acc_neuron = model_neuron.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Modifikasi Neuron - Loss: {loss_neuron:.4f}, Akurasi: {acc_neuron:.4f}\")\n",
    "\n",
    "# Bandingkan\n",
    "if acc_neuron > acc:\n",
    "    print(\"Result: Menambah neuron meningkatkan akurasi.\")\n",
    "else:\n",
    "    print(\"Result: Menambah neuron tidak berpengaruh signifikan/menurunkan performa (overfitting).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5b423",
   "metadata": {},
   "source": [
    "mengubah jumlah neuron pada hidden layer menjadi lebih besar (misalnya 2x lipat) untuk melihat apakah menambah \"kapasitas otak\" model akan meningkatkan akurasi atau justru tidak berpengaruh.\n",
    "\n",
    "Layer 1: Ubah 10 menjadi 20\n",
    "\n",
    "Layer 2: Ubah 8 menjadi 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82be04",
   "metadata": {},
   "source": [
    "# Tugas 3\n",
    "\n",
    "Bandingkan Sigmoid vs ReLU pada dataset Iris.\n",
    "\n",
    "Catat perbedaan loss dan akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODEL AKTIVASI SIGMOID ---\n",
      "Sigmoid - Loss: 0.7807, Akurasi: 0.6000\n",
      "Baseline (ReLU) - Loss: 0.2757, Akurasi: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- TUGAS 3: GANTI RELU DENGAN SIGMOID ---\n",
    "print(\"\\n--- MODEL AKTIVASI SIGMOID ---\")\n",
    "\n",
    "model_sigmoid = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)), # Ganti ke Sigmoid\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),                    # Ganti ke Sigmoid\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sigmoid = model_sigmoid.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Sigmoid - Loss: {loss_sigmoid:.4f}, Akurasi: {acc_sigmoid:.4f}\")\n",
    "print(f\"Baseline (ReLU) - Loss: {loss:.4f}, Akurasi: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ffbfb",
   "metadata": {},
   "source": [
    "Mengganti fungsi aktivasinya dari ReLU menjadi Sigmoid pada hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473b077",
   "metadata": {},
   "source": [
    "### 1. Analisis Baseline (Model Awal)\n",
    "* **Hasil:** Akurasi 1.0 (100%) | Loss: 0.2757\n",
    "* **Penjelasan:**\n",
    "    * Dataset Iris tergolong dataset sederhana. Dengan konfigurasi awal (10 neuron layer 1, 8 neuron layer 2), model sudah memiliki kapasitas yang cukup untuk memisahkan ke-3 jenis bunga dengan sempurna.\n",
    "    * **Pesan Warning:** `UserWarning: Do not pass an input_shape...` adalah peringatan bahwa sintaks Keras yang baru lebih menyukai penggunaan `Input(shape)` terpisah. Ini **tidak mempengaruhi hasil** (hanya masalah gaya penulisan kode).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Analisis Tugas 2 (Modifikasi Neuron: 20 & 16)\n",
    "* **Hasil:** Akurasi 1.0 (100%) | Loss: **0.1337** (Jauh lebih rendah dari Baseline 0.2757)\n",
    "* **Koreksi Kesimpulan Code:**\n",
    "    * Meskipun kode mencetak *\"Menambah neuron tidak berpengaruh signifikan\"*, itu hanya karena akurasi mentok di 100% (tidak bisa lebih tinggi lagi).\n",
    "    * **Fakta Sebenarnya:** Performa meningkat! Lihat nilai **Loss**-nya.\n",
    "    * **Loss 0.27 vs 0.13:**\n",
    "        * Loss **0.27** (Baseline): Model menebak benar, tapi mungkin tingkat keyakinannya sekitar 70-80%.\n",
    "        * Loss **0.13** (Modifikasi): Model menebak benar dengan tingkat keyakinan mendekati 90-95%.\n",
    "    * **Kesimpulan:** Menambah jumlah neuron membuat model menjadi lebih \"pintar\" dan **lebih percaya diri** (confident) dengan tebakannya, meskipun jumlah tebakan benarnya sama-sama 100%.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Analisis Tugas 3 (Sigmoid vs ReLU)\n",
    "Ini adalah bagian paling penting.\n",
    "* **Hasil Sigmoid:** Akurasi 0.60 (60%) | Loss: 0.7807\n",
    "* **Hasil ReLU:** Akurasi 1.0 (100%) | Loss: 0.2757\n",
    "* **Mengapa Sigmoid Hancur (Drop 40%)?**\n",
    "    1.  **Vanishing Gradient Problem:** Pada fungsi Sigmoid, turunan (gradient) di ujung-ujung kurva nilainya sangat kecil (mendekati 0). Ketika melakukan *backpropagation* (perambatan mundur), nilai update bobot menjadi sangat kecil. Akibatnya, model belajar **sangat lambat**.\n",
    "    2.  **Epoch Terbatas:** hanya melatih selama 50 epoch. Untuk ReLU, 50 epoch sudah lebih dari cukup. Untuk Sigmoid, 50 epoch belum cukup baginya untuk menemukan pola yang optimal karena lambatnya proses belajar tadi.\n",
    "    3.  **Saturasi:** Output Sigmoid terjepit antara 0 dan 1. Jika inisialisasi bobot tidak hati-hati, neuron bisa cepat \"jenuh\" (saturated) dan berhenti belajar.\n",
    "\n",
    "### Kesimpulan Akhir\n",
    "Dari eksperimen ini, kita bisa menyimpulkan:\n",
    "\n",
    "1.  **ReLU Superior:** Untuk *hidden layer*, ReLU hampir selalu lebih baik daripada Sigmoid karena proses belajarnya lebih cepat dan terhindar dari masalah gradien yang hilang (*vanishing gradient*).\n",
    "2.  **Kapasitas Model:** Menambah neuron (Task 2) menurunkan *loss* (error), yang berarti model semakin presisi memisahkan data, meskipun akurasinya sudah maksimal.\n",
    "3.  **Dataset Iris Mudah:** Karena dataset ini sederhana, model kecil (Baseline) pun sudah bisa mencapai akurasi 100%.\n",
    "\n",
    "**Saran:** Gunakan selalu **ReLU** untuk hidden layer, dan gunakan **Sigmoid/Softmax** hanya di output layer (tergantung binary atau multi-class)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
